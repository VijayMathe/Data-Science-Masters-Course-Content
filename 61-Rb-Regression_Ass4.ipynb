{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc9c6cb-e884-4894-9c38-bd6e8cac3f43",
   "metadata": {},
   "source": [
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207363e-c296-410c-a4a2-5898f3a1da87",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### Lasso Regression, short for Least Absolute Shrinkage and Selection Operator, is a linear regression technique that combines both regularization and feature selection.\n",
    "### It is similar to Ridge Regression but differs in the type of regularization used and its impact on the coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7afc25-49a7-484d-8bd4-a266e68d2e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "044a55ef-6574-4999-9277-f1427ca87108",
   "metadata": {},
   "source": [
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28012a2-0efd-48b9-a3b5-beb9d39f779b",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### The main advantage of using Lasso Regression for feature selection is its ability to automatically identify and select the most relevant features for predicting the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325cfa6-0469-42c3-abd9-3ff44d6e4aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8d40087-8200-4aba-b27c-d0eccb8bbcc3",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b027b-a36c-4909-b24a-d984af79eef9",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### Interpreting the coefficients of a Lasso Regression model requires some consideration due to the sparsity and feature selection nature of the method.\n",
    "\n",
    "### Non-Zero Coefficients: \n",
    "### Magnitude:\n",
    "### Zero Coefficients:\n",
    "### Relative Importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304e80c-6b0a-4792-bb1a-4bc28d31cd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d99eecdc-687b-4c29-b33d-c6b9181d2567",
   "metadata": {},
   "source": [
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b38214-7d11-46ca-aa6b-abb3771a2d0d",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### In Lasso Regression, there is a tuning parameter called \"alpha\" (Î±) that can be adjusted to control the balance between regularization and the least squares error term.\n",
    "### The value of alpha determines the type and strength of the regularization applied in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de40471-6a91-4d12-a399-39847ede7631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3ad3a93-39ed-491e-997e-e6d3bea2d81e",
   "metadata": {},
   "source": [
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b1c6e-fd6b-46c7-80ee-b05e431f1911",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### Lasso Regression, as a linear regression technique, is primarily designed for linear relationships between predictors and the response variable.\n",
    "### However, it can be extended to handle non-linear regression problems by incorporating non-linear transformations of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519683e-85f3-4c77-af34-f8e85e172e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "627dcceb-caff-4101-9a21-64e458aae3f6",
   "metadata": {},
   "source": [
    "### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121d154-48dc-4bb6-8079-4b87fc9dfdfc",
   "metadata": {},
   "source": [
    "### Ridge Regression uses L2 regularization, while Lasso Regression uses L1 regularization.\n",
    "\n",
    "### Ridge Regression does not perform feature selection and only reduces the magnitude of coefficients, while Lasso Regression performs feature selection by setting some coefficients to zero.\n",
    "\n",
    "### Ridge Regression handles multicollinearity by reducing the impact of correlated predictors, while Lasso Regression tends to select one representative variable from a group of correlated variables and sets the coefficients of the rest to zero.\n",
    "\n",
    "### Ridge Regression provides a more stable model, while Lasso Regression provides a more interpretable and sparse model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c98348-315c-4530-997a-43b932944555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35eafae3-a4ae-4048-944d-206605beced1",
   "metadata": {},
   "source": [
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50fa15-942f-4951-940e-1b6a1b05bc65",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### Yes, Lasso Regression can handle multicollinearity in the input features to some extent.\n",
    "\n",
    "### Variable Selection: Lasso Regression performs feature selection by setting some coefficients to zero. In the presence of multicollinearity, where predictors are highly correlated, Lasso Regression tends to select one representative variable from a group of correlated variables and sets the coefficients of the rest to zero.\n",
    "\n",
    "### Coefficient Shrinkage: Lasso Regression applies L1 regularization, which adds a penalty term proportional to the sum of the absolute values of the coefficients. This penalty encourages sparsity in the coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cafa035-e128-4f63-a885-be1ba8824374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568cf3b7-40a2-473b-86aa-71a0509985e5",
   "metadata": {},
   "source": [
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d8d94-2c75-4016-b42e-4cc8e004e3b4",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "To choose the optimal regularization parameter (lambda) in Lasso Regression:\n",
    "\n",
    "Cross-Validation: Use cross-validation to evaluate different lambda values and select the one that yields the best performance.\n",
    "\n",
    "Grid Search: Test various lambda values and choose the one that results in the best performance on a validation set.\n",
    "\n",
    "Information Criteria: Apply information criteria like AIC or BIC to find the lambda that minimizes the criterion.\n",
    "\n",
    "Lasso Path: Examine the behavior of coefficients as lambda varies to identify the value where important features enter or leave the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09abdd5-f7c9-4b59-a2f8-46def17bf92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
