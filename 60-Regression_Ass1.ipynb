{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd52044-6232-4cc8-a791-52ec750810f0",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f91c39-b7d6-4b06-9d3a-ff64048c324e",
   "metadata": {},
   "source": [
    "### Ans: \n",
    "### In the simple linear regression we have only one independent feature and one dependent feature. The model is trained on the basis of number of inputs and outputs. Then if we provide the new datapoint of the independent feature then the model will predict the dependent feature for that datapoint.\n",
    "### Here in the simple lineare regressio we find the best fit line. for the simple linear regression the equation for the best fit line is h0(x) = 0o + 01X.\n",
    "### In the multiple linear regression we have more that one independent features. The mode predicts the output for the combination of independent features.\n",
    "### Here we are having more than one independent features the we find a best fit palne. The equation for the best fit plane is (assuming there are two independent features) h0(X) = 0o + 01X1 + 02X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b7073-0add-4c99-90fa-76567520c201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "685640df-bbd1-4c5e-8cd7-b0b3621c3ac7",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd200e1-1591-4282-94f3-b2efae7589ef",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### The assumptions of linear regression are:\n",
    "### Linearity: The relationship between the dependent variable and the independent variables is linear. This means that the best fit line will be a straight line.\n",
    "### Homoscedasticity: The variance of the residuals is constant across all values of the independent variables. This means that the spread of the residuals is the same for all values of the independent variables.\n",
    "### Normality: The residuals are normally distributed. This means that the residuals are evenly distributed around zero and have a bell-shaped curve.\n",
    "### Independence: The residuals are independent of each other. This means that the value of one residual does not affect the value of another residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ea383-999c-4a5b-bb88-e9c50d257e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26a47ecb-808a-4563-96de-f55e6fd1f8ed",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf65ce0-8d9a-408a-a293-3530d70e2882",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### The equation for the best fit line in the simple linear regression is h0(X) = 0o + 01X\n",
    "### Here the 0o is the intercept mens when my x axis value is zero where does my best fit line meets to the y axis.\n",
    "### and the 01X is the slope or the coefficient. It meens that with the unit movement in the x axis how musch movement i am having on the y axis\n",
    "### The slope represents the rate of change between the dependent and independent variables, while the intercept represents the value of the dependent variable when the independent variable is 0.\n",
    "### For example, let's say that we are interested in the relationship between the number of hours that a student studies and their grade on a test. We collect data on 100 students and find that the following linear regression model fits the data well:\n",
    "\n",
    "### grade = 0.5 * hours_studied + 60\n",
    "### In this model, the slope is 0.5, which means that for every additional hour that a student studies, their grade is expected to increase by 0.5 points. The intercept is 60, which means that if a student studies for 0 hours, their expected grade is 60.\n",
    "### This model can be used to predict the grade of a student who studies for a certain number of hours. For example, if a student studies for 2 hours, their predicted grade is 61.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e52bb6-16dc-499a-a856-38bd88c55005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40cfc015-ad19-4265-9f30-43096bbf4f24",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17169076-d785-4c7e-b389-5214cdf60de7",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### As we know that in a simple linear regression we have to find the best fit line and we need to ensure that the error between the actual and the predicted data points must less. So in order to overcome the error we need to apply optimization procedure to the best fit line. In optimization procedure we apply a convergence algorithm. we calculate a cost function to each of the 0o and the 01 values and we basically come to the global minima where the error with respect to the best fit line will be lesser. The curve we get by connecting all the cost function points we get a gradient descent curve.\n",
    "### we can use the gradient descent to minimize the errors between the actual and the predicted points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289002e-3171-4471-a8bb-80f276af5406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1db27a16-ff90-4e38-87ad-2f532ec31777",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15c8af-ce78-47ea-a022-8b18bd2bd641",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### Multiple linear regression is a statistical method that predicts a dependent variable from multiple independent variables. In simple linear regression, there is only one independent variable. In multiple linear regression, there are two or more independent variables.\n",
    "### The multiple linear regression model is a linear equation that predicts the dependent variable from the independent variables. The equation is:\n",
    "### y = b0 + b1x1 + b2x2 + ... + bnxn\n",
    "### where:\n",
    "### y is the dependent variable\n",
    "### b0 is the intercept\n",
    "### b1, b2, ..., bn are the slopes for the independent variables x1, x2, ..., xn\n",
    "### x1, x2, ..., xn are the independent variables\n",
    "### The slopes of the independent variables tell us how much the dependent variable changes when the independent variable is changed by one unit. The intercept tells us the value of the dependent variable when all of the independent variables are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f73b1e-8c00-487b-afbe-a24272cee75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8975f579-fefd-4877-9bb2-428d85f05f39",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f8aea-6ddb-4d28-9baf-dc145e1cc50b",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### Multicollinearity is a statistical phenomenon in which two or more independent variables in a multiple linear regression model are highly correlated with each other. This can cause problems with the model, such as:\n",
    "\n",
    "### The standard errors of the coefficients may be inflated, making it difficult to determine which variables are statistically significant.\n",
    "### The p-values for the coefficients may be too low, leading to false positives.\n",
    "### The model may be unstable, meaning that small changes in the data can lead to large changes in the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768030b4-b23b-43c1-869b-7d4d4286d3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5024629d-3019-44c1-b5cd-0ef7631dcce6",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fac044-dfb2-47ce-83ad-0fce68f66f5c",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### in the polynomial regression the relation between the dependent and the independent variables is not linear. \n",
    "### for finding the best fit line we use a polynomial degrees, as the degree increases the error between the actual and the predicted data point decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b018e-2f23-4088-bbca-2f4714072b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1517649-5920-452a-81b0-227cf6c84f73",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac53a1-52d8-4522-be01-2a44dfc0d4bd",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "### -Advantages of polynomial regression:\n",
    "\n",
    "### Can model nonlinear relationships between the dependent and independent variables.\n",
    "### Can be more accurate than linear regression when the relationship between the dependent and independent variables is nonlinear.\n",
    "### Can be used to fit a wider range of data than linear regression.\n",
    "### -Disadvantages of polynomial regression:\n",
    "\n",
    "### More complex than linear regression.\n",
    "### More difficult to interpret than linear regression.\n",
    "### Can be more sensitive to outliers than linear regression.\n",
    "### - When to use polynomial regression:\n",
    "\n",
    "### When the relationship between the dependent and independent variables is nonlinear.\n",
    "### When you need a more accurate model than linear regression can provide.\n",
    "### When you need to fit a wider range of data than linear regression can accommodate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd15d6-df04-4959-961a-c063b9aa4b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
